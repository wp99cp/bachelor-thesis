# Working Pipeline

This page describes the pipelines used to train the model.

## High-Level Overview

The pipeline consists of the following steps:

1) Download the raw data from the server. On Euler this step is always skipped.
2) Automatically annotate the raw data (using a mixture of existing models)
3) Create the training dataset
4) Train and validate the ML model

The pipeline can be executed using the following command:

```bash
bash helper-scripts/pipeline.sh pipeline-config.yml 
```

## Configuration

The pipeline is configured using the `config.yaml` file.

```yml
# deletes the results folder before starting the pipeline (1 or 0), ignored on euler
clear_results: 0

data_handling:

  # forces to download the raw data from the pf-server (1 or 0), ignored on euler
  force_rsync: 0

  # ignored on euler
  force_extraction: 0

  # use single quotes for the dates and the array syntax
  s2_dates: [ '20211008T101829', '20210710T101559', '20210106T102411', '20210406T102021' ]

annotation:

  # use the auto annotator to create the ground truth (1 or 0)
  auto_annotation: 0

dataset:

  recreate_dataset: 1

```

## Special Case Euler

On Euler the pipeline is slightly different. Step (1) is never executed. Instead, the raw data must be already available
on the cluster. For that please upload a ZIP file called `raw_data.zip` containing the raw data in the following
structure:

```
- raw
 | - raw_data_32TNS_1C
 | - raw_data_32TNS_2A
 | - 32TMS_auxiliary_data.zip
 | - ExoLabs_classification_S2.zip
 | - swiss_map_tile.tif
```

Optionally (i.g. if step (2) is skipped). You can provide a second zip file called `annotated_masks.zip` containing the
autogenerated masks in the following structure:

```
- annotated_masks
 | - 2021...
 | - ....
```

