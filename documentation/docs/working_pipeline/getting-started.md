# Getting Started <br /> Snow and Cloud Segmentation

This is the documentation for my bachelor thesis. It contains all the information needed to reproduce the results, train
the model, and run inference on new images. Please follow the instructions to get started.

- [Installation and Setup](#installation-and-setup)
- [Setting Environments Variables](#getting-started-on-different-devices)
- [Folder Structure and Data Organization](#folder-structure-and-data-organization)
- [The Main Programm: The End-to-End-Pipeline](/docs/working_pipeline/pipeline.html)

## Installation and Setup

Before you can get started, you need to install the necessary dependencies.

::: danger
This is not yet documented. See [Python and Conda
](/docs/nice_to_know/python_and_conda) for the meanwhile.
:::

## Getting Started on Different Devices

The segmentation pipelines is designed to work on different devices with potentially different file structures, thus it
is unavoidable to set some environment variables. The following sections describe how to set the environment variables.

::: details Working with pf-pc20

Here all data associated with the project is stored within the `/projects/bachelor-thesis` folder.

The following commands are saved in the `~/.bashrc` file, thus you don't need to execute them manually.
However, for the sake of completeness, they are listed here:

```bash
# project base directory
export BASE_DIR=/scratch2/pucyril/bachelor-thesis

# used to store the data (e.g. training sets, annotations, etc.)
export DATA_DIR=$BASE_DIR/data
export DATA_RAW_DIR=$DATA_DIR/raw
export ANNOTATED_MASKS_DIR=$DATA_DIR/annotated_masks
export MASKS_DIR=$DATA_DIR/masks
export DATASET_DIR=$DATA_DIR/dataset

export RAW_DATA_REMOTE_DIR=/home/pf/pfstud/nimbus/download_data

# here the results are stored (e.g. model checkpoints, tensorboard logs, etc.)
export RESULTS_DIR=$BASE_DIR/results

# used to sore some temporary files (non-persistent)
export TMP_DIR=$BASE_DIR/tmp
export EXTRACTED_RAW_DATA=$BASE_DIR/tmp

# add additional python paths
export PYTHONPATH="${PYTHONPATH}:/scratch2/pucyril/python"

# cleanup
# find $TMP_DIR -type f ! -name '.gitignore' -delete
# find $TMP_DIR -type d -empty -delete

```

:::

::: details Working with Laptop

Here all data associated with the project is stored within the `/projects/bachelor-thesis` folder.

```bash
# mount network shares
sshfs -o default_permissions pucyril@pf-pc20.ethz.ch:/home/pf/pfstud/nimbus /mnt/nimbus

# project base directory
export BASE_DIR=/projects/bachelor-thesis

# used to store the data (e.g. training sets, annotations, etc.)
export DATA_DIR=$BASE_DIR/data
export DATA_RAW_DIR=$DATA_DIR/raw
export ANNOTATED_MASKS_DIR=$DATA_DIR/annotated_masks
export MASKS_DIR=$DATA_DIR/masks
export DATASET_DIR=$DATA_DIR/dataset

export RAW_DATA_REMOTE_DIR=/mnt/nimbus/download_data

# here the results are stored (e.g. model checkpoints, tensorboard logs, etc.)
export RESULTS_DIR=$BASE_DIR/results

# used to sore some temporary files (non-persistent)
export TMP_DIR=$BASE_DIR/tmp
export EXTRACTED_RAW_DATA=$BASE_DIR/tmp

# cleanup
# find $TMP_DIR -type f ! -name '.gitignore' -delete
# find $TMP_DIR -type d -empty -delete
```

:::

::: details Working with Euler
Here all data management is handled by the ansible scripts. Details can be
found [in the section about Euler](/docs/nice_to_know/euler.html).
:::

## Folder Structure and Data Organization

The data organization for a project of that size is crucial.

As we are working on three different machines (desktop, cluster, and laptop), each machine uses a slightly different
folder structure (e.g. on Euler we are heavily utilizing the properties of the different file systems).

Thus make sure to export the environment variables before starting,
see [Getting Started on Different Devices](#getting-started-on-different-devices).

### High-Level Folder Structure

- `data`: used to store the data (e.g. training sets, raw data, annotations, etc.)
    - `raw`: used to store the raw data (this is just a partial clone of the pf file server)
    - `annotated_masks`: used to store **hand** annotated masks
    - `ground_truth`: used to store the **ground truth** masks (this may just be a symlink to `annotated_masks`)
    - `masks`: used to store **autogenerated** masks and cleaned masks
    - `dataset`: used to store the dataset for training
- `results`: here the results are stored (e.g. model checkpoints, tensorboard logs, etc.)
- `tmp`: used to sore some temporary files (non-persistent)
- `backup`: used for temporary local backups
